{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Import your libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import re\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Challenge 1 -  Explore the Internal Dataset\n",
    "\n",
    "In this lab, we will start off by working with the wine dataset in scikit-learn. We will select the wine dataset and use a clustering algorithm to learn more about the functionalities of this library. \n",
    "\n",
    "We start off by loading the dataset using the `load_wine` function ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)). In the cell below, we will import the function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In the cell below, use the `load_wine` function and assign the wine dataset to a variable called `wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In the next step, list the keys of the variable `wine` to examine its contents. Note that the `load_wine` function does not return dataframes. It returns you a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, list the feature names. These are the different characteristics of the wine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Print the description of the dataset in the cell below using the `DESCR` attribute of the `wine` variable.\n",
    "\n",
    "*Hint: If your output is ill-formatted by displaying linebreaks as `\\n`, it means you are not using the print function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### From the description, we see that all columns are numeric. We also know that there is no missing data \n",
    "\n",
    "Let's plot the alcohol content histogram. Recall that we are working with a numpy array and will need to use a matplotlib function to produce a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here:\n",
    "sns.displot(wine.data[:,0],kde=False,bins=25)\n",
    "plt.xlabel('Alcohol %')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution alcohol % dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Challenge 2 - Clustering the Internal Dataset\n",
    "\n",
    "In this portion of the lab, we will cluster the data to find common traits between the different wines. We will use the k-means clustering algorithm to achieve this goal.\n",
    "\n",
    "#### We start by importing k-means from scikit-learn and then proceed to create 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "X = np.array(wine.data)\n",
    "model = KMeans(n_clusters=4).fit(X)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Print the cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 2, 2,\n",
       "       1, 1, 1, 2, 3, 3, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 1, 1, 1, 3, 3, 0, 2, 0, 2, 0, 0, 2,\n",
       "       0, 0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "       2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2,\n",
       "       2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "       2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1,\n",
       "       1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Compute the size of each cluster. This can be done by counting the number of occurrences of each unique label in the list above.\n",
    "\n",
    "Which is the largest cluster of the 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    59\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "pd.DataFrame(model.labels_).value_counts().sort_values(ascending=False)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Inspect the shape of `wine['data']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- There are 178 wines in our dataset\n",
      "\n",
      "- We have 13 features in the wine dataset\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(\"\"\"\n",
    "- There are {0} wines in our dataset\n",
    "\n",
    "- We have {1} features in the wine dataset\n",
    "\n",
    "\"\"\".format(\n",
    "wine['data'].shape[0],\n",
    "wine['data'].shape[1])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Inspect the first 5 records in `wine['data']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n",
       "        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, 1.860e+01, 1.010e+02, 2.800e+00,\n",
       "        3.240e+00, 3.000e-01, 2.810e+00, 5.680e+00, 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n",
       "        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n",
       "        1.480e+03],\n",
       "       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n",
       "        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n",
       "        7.350e+02]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "wine['data'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You now know the data object is a 2-dimensional array in which there are 178 rows and 13 columns. Each row is a data record and each column is a feature.\n",
    "\n",
    "#### What is the average ash content for each cluster? \n",
    "\n",
    "*Hints:* \n",
    "\n",
    "* *Ash* is the 3rd column.\n",
    "\n",
    "* The data object is not a Pandas dataframe so you can't apply `pandas.DataFrame.groupby`. Instead, you can use `np.average`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusters</th>\n",
       "      <th>ash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.282542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.374865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.390508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.506957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusters       ash\n",
       "0       0.0  2.282542\n",
       "1       1.0  2.374865\n",
       "2       2.0  2.390508\n",
       "3       3.0  2.506957"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.DataFrame(data=np.c_[wine['data'],model.labels_,],\n",
    "             columns = wine['feature_names'] + ['clusters'])\n",
    "\n",
    "total.groupby('clusters')['ash'].agg(np.average).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Challenge 3 - Load and Explore an External Dataset\n",
    "\n",
    "We will now load an external dataset using Pandas and use scikit learn to explore the data. In this portion of the lab, we will use a [patient dataset from Kaggle](https://www.kaggle.com/miles99/patient-admission-dataset-for-learning-data-mining). Download it from [here](https://drive.google.com/file/d/1jIGrckDaQ7_rtCSzqyuTiCyAhmliyBAS/view?usp=sharing) and place it in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/patient-admission-dataset-for-learning-data-mining.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In the next cell, print the first five rows of the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>patient_email</th>\n",
       "      <th>doctor_phone</th>\n",
       "      <th>patient_gender</th>\n",
       "      <th>patient_dob</th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>patient_nhs_number</th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>appointment_date</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>prescribed_medicines</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Celestyna Dillimore</td>\n",
       "      <td>cdillimore0@dion.ne.jp</td>\n",
       "      <td>674-914-1212</td>\n",
       "      <td>Female</td>\n",
       "      <td>10/18/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>59</td>\n",
       "      <td>176</td>\n",
       "      <td>8.200152e+09</td>\n",
       "      <td>Sarena Waliszek</td>\n",
       "      <td>5/1/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>triamcinolone acetonide</td>\n",
       "      <td>I669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Meta Michieli</td>\n",
       "      <td>mmichieli1@loc.gov</td>\n",
       "      <td>172-580-3586</td>\n",
       "      <td>Female</td>\n",
       "      <td>2/8/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Farris Robinet</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cordie Sancto</td>\n",
       "      <td>csancto2@cafepress.com</td>\n",
       "      <td>794-222-5085</td>\n",
       "      <td>Female</td>\n",
       "      <td>10/9/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>6.145594e+09</td>\n",
       "      <td>Kaspar Spitaro</td>\n",
       "      <td>10/5/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Josh De Ambrosis</td>\n",
       "      <td>jde3@amazon.co.jp</td>\n",
       "      <td>856-540-5195</td>\n",
       "      <td>Male</td>\n",
       "      <td>9/10/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rafferty Fowls</td>\n",
       "      <td>10/21/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Delinda Alfonsini</td>\n",
       "      <td>dalfonsini4@opensource.org</td>\n",
       "      <td>938-978-1131</td>\n",
       "      <td>Female</td>\n",
       "      <td>2/26/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "      <td>140</td>\n",
       "      <td>4.804758e+08</td>\n",
       "      <td>Glenna MacNeachtain</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         patient_name               patient_email  doctor_phone  \\\n",
       "0   1  Celestyna Dillimore      cdillimore0@dion.ne.jp  674-914-1212   \n",
       "1   2        Meta Michieli          mmichieli1@loc.gov  172-580-3586   \n",
       "2   3        Cordie Sancto      csancto2@cafepress.com  794-222-5085   \n",
       "3   4     Josh De Ambrosis           jde3@amazon.co.jp  856-540-5195   \n",
       "4   5    Delinda Alfonsini  dalfonsini4@opensource.org  938-978-1131   \n",
       "\n",
       "  patient_gender patient_dob  patient_diabetic  patient_allergic  \\\n",
       "0         Female  10/18/2018             False              True   \n",
       "1         Female    2/8/2018             False              True   \n",
       "2         Female   10/9/2018              True              True   \n",
       "3           Male   9/10/2018              True              True   \n",
       "4         Female   2/26/2018             False              True   \n",
       "\n",
       "   patient_weight_kg  patient_height_sm  patient_nhs_number  \\\n",
       "0                 59                176        8.200152e+09   \n",
       "1                 77                186                 NaN   \n",
       "2                 90                177        6.145594e+09   \n",
       "3                 70                150                 NaN   \n",
       "4                 82                140        4.804758e+08   \n",
       "\n",
       "           doctor_name appointment_date  patient_show  is_regular_visit  \\\n",
       "0      Sarena Waliszek         5/1/2018          True              True   \n",
       "1       Farris Robinet        12/7/2017          True              True   \n",
       "2       Kaspar Spitaro        10/5/2018         False             False   \n",
       "3       Rafferty Fowls       10/21/2018         False              True   \n",
       "4  Glenna MacNeachtain       11/15/2018         False             False   \n",
       "\n",
       "      prescribed_medicines diagnosis  \n",
       "0  triamcinolone acetonide      I669  \n",
       "1                      NaN       NaN  \n",
       "2                      NaN       NaN  \n",
       "3                      NaN       NaN  \n",
       "4                      NaN       NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, print the column types and check which columns have been misclassified by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        int64\n",
       "patient_name             object\n",
       "patient_email            object\n",
       "doctor_phone             object\n",
       "patient_gender           object\n",
       "patient_dob              object\n",
       "patient_diabetic           bool\n",
       "patient_allergic           bool\n",
       "patient_weight_kg         int64\n",
       "patient_height_sm         int64\n",
       "patient_nhs_number      float64\n",
       "doctor_name              object\n",
       "appointment_date         object\n",
       "patient_show               bool\n",
       "is_regular_visit           bool\n",
       "prescribed_medicines     object\n",
       "diagnosis                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### We can see that none of the date columns have been correctly classified. Also, some columns contain qualitative data that can be dropped.\n",
    "\n",
    "First, transform the `patient_dob` and `appointment_date` columns to datetime using the `pd.to_datetime` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "for col in df[['patient_dob','appointment_date']].columns:\n",
    "    df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, drop the `id`, `patient_name`, `patient_email`, `patient_nhs_number`, and `doctor_phone` columns. These are not quantitative columns and will not contribute to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df.drop(columns = ['id', \n",
    "                   'patient_name', \n",
    "                   'patient_email', \n",
    "                   'patient_nhs_number',  \n",
    "                   'doctor_phone'  ] , \n",
    "                    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now we work on the missing data. Most ML algorithms will not perform as intended if there are missing data.\n",
    "\n",
    "In the cell below, count how many rows contain missing data in each column. You should see three columns contain missing data:\n",
    "\n",
    "* `doctor_name`: 58 missing data\n",
    "* `prescribed_medicines`: 488 missing data\n",
    "* `diagnosis`: 488 missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_gender            0\n",
       "patient_dob               0\n",
       "patient_diabetic          0\n",
       "patient_allergic          0\n",
       "patient_weight_kg         0\n",
       "patient_height_sm         0\n",
       "doctor_name              58\n",
       "appointment_date          0\n",
       "patient_show              0\n",
       "is_regular_visit          0\n",
       "prescribed_medicines    488\n",
       "diagnosis               488\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The main issues are found in the `prescribed_medicines` and `diagnosis` columns. Can we simply drop these rows?\n",
    "\n",
    "The answer is not yet. Because when there are missing data in these columns, it doesn't mean the data records are broken. Instead, it means no medication was prescribed and no diagnosis was recorded. Therefore, once we fill in the missing data these columns will be fine. But we'll revisit these columns and decide whether we will eventually drop them when we look at how many unique values are there in these categorical columns.  \n",
    "\n",
    "For the `prescribed_medicines` column, fill the missing values with the value `no prescription`. For the `diagnosis` column, fill the missing values with `no diagnosis`.\n",
    "\n",
    "*Hint: Use [`pandas.DataFrame.fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df.prescribed_medicines.fillna('no prescription' , inplace = True)\n",
    "\n",
    "df.diagnosis.fillna('no diagnosis', inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "How about `doctor_name`? Since a doctor visit without a doctor name might not be meaningful, we will drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Another step in preprocessing that can be performed by scikit-learn is label encoding. \n",
    "\n",
    "We have 4 columns that are of `bool` type. We would like to convert them to an integer column containing either zero or one. We can do this using [scikit-learn's label encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "In the cell below, import the label encoder and encode the 4 boolean columns (*patient_diabetic*, *patient_allergic*, *patient_show*, *is_regular_visit*) with `0` and `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df[['patient_diabetic',\n",
    "           'patient_allergic',\n",
    "           'patient_show',\n",
    "           'is_regular_visit']].columns:\n",
    "    le.fit(df[col])\n",
    "    df[col] =  le.transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Print the data dtypes to confirm those four `bool` columns are converted to `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_gender                  object\n",
       "patient_dob             datetime64[ns]\n",
       "patient_diabetic                 int64\n",
       "patient_allergic                 int64\n",
       "patient_weight_kg                int64\n",
       "patient_height_sm                int64\n",
       "doctor_name                     object\n",
       "appointment_date        datetime64[ns]\n",
       "patient_show                     int64\n",
       "is_regular_visit                 int64\n",
       "prescribed_medicines            object\n",
       "diagnosis                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### The last step is to handle the `object` data.\n",
    "\n",
    "There are 4 `object` columns now: `patient_gender`, `doctor_name`, `prescribed_medicines`, and `diagnosis`. The gender columns\n",
    "\n",
    "In the next cell, check the unique values of each of the `object` columns using `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_gender            2\n",
       "doctor_name              19\n",
       "prescribed_medicines    395\n",
       "diagnosis               485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df[['patient_gender',\n",
    "    'doctor_name',\n",
    "   'prescribed_medicines',\n",
    "   'diagnosis']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### The number of unique values is large for all three columns except `patient_gender`. We will handle these columns differently.\n",
    "\n",
    "For `diagnosis`, there are too many unique values which will make ML difficult. However, we can re-encode the values to either with or without diagnosis. Remember at an earlier step we filled in the missing values of this column with *no diagnosis*? We can re-encode *no diagnosis* to `0` and all other values to `1`. In this way we can tremendously simply this column.\n",
    "\n",
    "For `prescribed_medicines`, we can drop this column because it is perfectly correlated with `diagnosis`. Whenever there is no diagnosis, there is no prescribed medicine. So we don't need to keep this duplicated data.\n",
    "\n",
    "How about `doctor_name`? There are not excessive unique values but still quite many (19). We may either drop or keep it but keeping it will make the analysis more complicated. So due to the length of this lab let's drop it.\n",
    "\n",
    "How about `gender`? This one is easy. Just like re-encoding the boolean values, we can re-encode gender to `0` and `1` because there are only 2 unique values.\n",
    "\n",
    "In the next cells, do the following:\n",
    "\n",
    "1. Create a new column called `diagnosis_int` that has `0` and `1` based on the values in `diagnosis`.\n",
    "\n",
    "1. Create a new column called `patient_gender_int` that has `0` and `1` based on the values in `patient_gender`.\n",
    "\n",
    "1. Drop the following columns: `doctor_name`, `diagnosis`, `prescribed_medicines`, and `patient_gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df['diagnosis_int'] = df.diagnosis.apply(lambda x : 0 if x == 'no diagnosis' else 1)\n",
    "df['patient_gender_int'] = le.fit(df['patient_gender']).transform(df['patient_gender'])\n",
    "\n",
    "df.drop(columns = ['doctor_name',\n",
    "                   'diagnosis',\n",
    "                   'prescribed_medicines',\n",
    "                   'patient_gender'\n",
    "                    ] , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's look at the head again to ensure the re-encoding and dropping are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_dob</th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>appointment_date</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>diagnosis_int</th>\n",
       "      <th>patient_gender_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>176</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>186</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>140</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>154</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>182</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>157</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>140</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_dob  patient_diabetic  patient_allergic  patient_weight_kg  \\\n",
       "0    2018-10-18                 0                 1                 59   \n",
       "1    2018-02-08                 0                 1                 77   \n",
       "2    2018-10-09                 1                 1                 90   \n",
       "3    2018-09-10                 1                 1                 70   \n",
       "4    2018-02-26                 0                 1                 82   \n",
       "..          ...               ...               ...                ...   \n",
       "994  2018-02-06                 1                 0                108   \n",
       "996  2018-10-29                 0                 1                 52   \n",
       "997  2018-01-11                 1                 1                 91   \n",
       "998  2018-05-20                 0                 1                 63   \n",
       "999  2018-06-04                 0                 0                 99   \n",
       "\n",
       "     patient_height_sm appointment_date  patient_show  is_regular_visit  \\\n",
       "0                  176       2018-05-01             1                 1   \n",
       "1                  186       2017-12-07             1                 1   \n",
       "2                  177       2018-10-05             0                 0   \n",
       "3                  150       2018-10-21             0                 1   \n",
       "4                  140       2018-11-15             0                 0   \n",
       "..                 ...              ...           ...               ...   \n",
       "994                157       2018-05-10             1                 1   \n",
       "996                154       2017-12-12             1                 1   \n",
       "997                182       2018-05-17             1                 1   \n",
       "998                157       2017-12-15             1                 1   \n",
       "999                140       2018-07-10             1                 0   \n",
       "\n",
       "     diagnosis_int  patient_gender_int  \n",
       "0                1                   0  \n",
       "1                0                   0  \n",
       "2                0                   0  \n",
       "3                0                   1  \n",
       "4                0                   0  \n",
       "..             ...                 ...  \n",
       "994              0                   0  \n",
       "996              0                   0  \n",
       "997              0                   1  \n",
       "998              1                   1  \n",
       "999              1                   1  \n",
       "\n",
       "[942 rows x 10 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "An interesting observation is that all patients are no older than 2 years. However, their weights and heights indicate that they are adults. This cannot be true. Therefore, we can either trust the weight and height columns or the DOB column. Since there are other columns that indicate that these are adults (they have emails, some have diabetes) we will drop the `patient_dob` column. We will also drop the `appointment_date` column since it has too many unique values to transform to a dummy variable. Drop the two columns in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['patient_diabetic', 'patient_allergic', 'patient_weight_kg',\n",
      "       'patient_height_sm', 'patient_show', 'is_regular_visit',\n",
      "       'diagnosis_int', 'patient_gender_int'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.drop(columns = ['patient_dob','appointment_date'] ,inplace = True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Our data is now ready for clustering. Let's use k-means again.\n",
    "\n",
    "We start by initializing and fitting a model in the cell below. Call this model patients_cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "data = np.array(df)\n",
    "\n",
    "patients_cluster = KMeans(n_clusters=4)\n",
    "patients_cluster.fit(data)\n",
    "y_pred = patients_cluster.predict(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Attach the labels to the dataframe. Do this by accessing the `labels_` in the `patients_cluster` model and assign them to a new column in `patients` that you will call `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "df['labels'] = patients_cluster.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now using a `groupby`, find the mean of every variable in `patients` and group by the `labels` column. This summary will allow us to see how the patients differ between the clusters. Your output should look similar to the image below [groupby mean](https://drive.google.com/file/d/1-YU2i7KrwXuBohkOKT2gR4HbUvM7nJAt/view?usp=sharing)\n",
    "\n",
    "Additionally, add a comment to describe which columns have the largest difference between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_diabetic</th>\n",
       "      <th>patient_allergic</th>\n",
       "      <th>patient_weight_kg</th>\n",
       "      <th>patient_height_sm</th>\n",
       "      <th>patient_show</th>\n",
       "      <th>is_regular_visit</th>\n",
       "      <th>diagnosis_int</th>\n",
       "      <th>patient_gender_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485944</td>\n",
       "      <td>0.485944</td>\n",
       "      <td>94.112450</td>\n",
       "      <td>178.847390</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.457831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.491304</td>\n",
       "      <td>65.365217</td>\n",
       "      <td>152.304348</td>\n",
       "      <td>0.508696</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.552174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560538</td>\n",
       "      <td>0.529148</td>\n",
       "      <td>97.381166</td>\n",
       "      <td>153.529148</td>\n",
       "      <td>0.488789</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.596413</td>\n",
       "      <td>0.520179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62.900000</td>\n",
       "      <td>176.954167</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>0.454167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_diabetic  patient_allergic  patient_weight_kg  \\\n",
       "labels                                                          \n",
       "0               0.485944          0.485944          94.112450   \n",
       "1               0.504348          0.491304          65.365217   \n",
       "2               0.560538          0.529148          97.381166   \n",
       "3               0.508333          0.533333          62.900000   \n",
       "\n",
       "        patient_height_sm  patient_show  is_regular_visit  diagnosis_int  \\\n",
       "labels                                                                     \n",
       "0              178.847390      0.506024          0.530120       0.510040   \n",
       "1              152.304348      0.508696          0.556522       0.504348   \n",
       "2              153.529148      0.488789          0.506726       0.596413   \n",
       "3              176.954167      0.475000          0.495833       0.454167   \n",
       "\n",
       "        patient_gender_int  \n",
       "labels                      \n",
       "0                 0.457831  \n",
       "1                 0.552174  \n",
       "2                 0.520179  \n",
       "3                 0.454167  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "df.groupby('labels').agg(np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Seems that the groups seems to be predominantly divided by height and weight. But not suprisingly certain groups score high \n",
      "on the diabetic and diagnosis score.\n",
      "\n",
      "- smaller people which have a high weight are bit more often diabetic and have often a high diagnosises. This group seems \n",
      "to have a higher proportion of females \n",
      "\n",
      "- smaller people which have a light weight are bit more often diabetic, female dominant  \n",
      "\n",
      "- taller people with a lower weight , male dominant\n",
      "\n",
      "- taller people with high weight , male dominant\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your comment here:\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "Seems that the groups seems to be predominantly divided by height and weight. But not suprisingly certain groups score high \n",
    "on the diabetic and diagnosis score.\n",
    "\n",
    "- smaller people which have a high weight are bit more often diabetic and have often a high diagnosises. This group seems \n",
    "to have a higher proportion of females \n",
    "\n",
    "- smaller people which have a light weight are bit more often diabetic, female dominant  \n",
    "\n",
    "- taller people with a lower weight , male dominant\n",
    "\n",
    "- taller people with high weight , male dominant\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Bonus Challenge: Visualize K-Means Clusters\n",
    "\n",
    "How did k-means cluster the data? You can obtain an intuitive view with a scatter plot. Generate a 2-d cluster plot below using `matplotlib`. You need to choose 2 of the features from your cleaned and transformed dataset, and use color to represent the cluster label generated from k-means.\n",
    "\n",
    "If the scatter plot does not make any sense to you, it means the features you chose to visualize are not the right ones. You should be able to see 4 clear clusters with different colors in your visualization that suggests how k-means had clustered your data.\n",
    "\n",
    "[Cluster Visualization](https://drive.google.com/file/d/1J-LvaSnS--6Zz8wYfsb3k-2CA4KcyQfm/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Additionally, you can visualize the clusters in 3-D scatter plot. Give it a try below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
