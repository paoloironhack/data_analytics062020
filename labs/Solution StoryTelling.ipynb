{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Storytelling Data Visualization Lab\n",
    "\n",
    "In this lab you'll use a dataset called `housing_prices.csv` which contains the sales data of houses. The dataset and descriptions of the columns are available from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). For your convenience, you can review the descriptions of the data columns from [here](data/data-description.txt).\n",
    "\n",
    "Pretend you are a data analyst at an investment company where the board decided to make investments in real estates. Your boss asked you to analyze this housing sales dataset and present to the investment managers on **what features of houses are strong indicators of the final sale price**. You need to present your findings in intuitive ways so that the investment managers understand where your conclusions come from.\n",
    "\n",
    "#### You will use the appropriate data visualization graphs to tell your stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 1 - Understanding the Dataset\n",
    "\n",
    "After receiving the data and clarifying your objectives with your boss, you will first try to understand the dataset. This allows you to decide how you will start your research in the next step.\n",
    "\n",
    "#### First, import the basic libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/housing_prices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7337cf238e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/housing_prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.0/libexec/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.0/libexec/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.0/libexec/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.0/libexec/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.0/libexec/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/housing_prices.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/housing_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### As a routine before analyzing a dataset, print the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You find the dataset has 81 columns which are a lot. \n",
    "\n",
    "#### Since the column `Id` is meaningless in our data visualization work, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You care about missing values. If a column has too many missing values, it is not reliable to use it to predict sales price.\n",
    "\n",
    "#### In the cell below, calculate the percentage of missing values for each column. \n",
    "\n",
    "Make a table containing the column name and the percentage of missing values. Print the columns where more than 20% of values are missing. An example of your output looks like:\n",
    "\n",
    "![Missing Values](images/missing-values.png)\n",
    "\n",
    "[This reference](https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset) can help you make the missing values table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Find the % of missing values\n",
    "prcnt_nan = pd.DataFrame({'column_name': df.columns, \n",
    "                          'percent_missing': df.isnull().sum() / len(df) * 100}).reset_index(drop=True)\n",
    "\n",
    "# Find the columns where more than 20% of values are missing\n",
    "more_20_nan = prcnt_nan[prcnt_nan['percent_missing'] > 20].sort_values(by='percent_missing', ascending=False)\n",
    "more_20_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Drop the columns you find that have more than 20% missing values.\n",
    "\n",
    "After dropping, check the shape of your dataframes. You should have 75 columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.drop(more_20_nan['column_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Since you're asked to analyze sale prices, first let's see if the sale prices (column `SalePrice`) has a normal distribution. This is important because normally distributed data can be better represented with mathematical models.\n",
    "\n",
    "#### In the cell below, use the propriate graph to visualize the shape of distribution of the sale prices. Then explain what you find from the graph about data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df['SalePrice'], bins=70)\n",
    "plt.title('Histogram of Sale Price', fontweight=600)\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`Comments:`<br/>\n",
    "The distribution is an inverse Gaussian distribution as it is a right-skewed distribution bounded at zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bonus Challenge 1 - Adjust Data Distribution\n",
    "\n",
    "If you used the correct method in the previous step, you should have found the data distribution is skewed to the right. In order to improve your data visualization in the next steps, you can opt to adjust the `SalePrice` column by applying a mathematical function to the values. The goal is to produce a bell-shape normal distribution after applying the mathematical function to the sale price.\n",
    "\n",
    "*This technique is optional in data visualization but you'll find it useful in your future machine learning analysis.*\n",
    "\n",
    "#### In the cell below, adjust the `SalePrice` column so that the data are normally distributed.\n",
    "\n",
    "Try applying various mathematical functions such as square root, power, and log to the `SalePrice` column. Visualize the distribution of the adjusted data until you find a function that makes the data normally distributed. **Create a new column called `SalePriceAdjusted` to store the adjusted sale price.**\n",
    "\n",
    "[This reference](https://trainingdatascience.com/workshops/histograms-and-skewed-data/) shows you examples on how to adjust skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Calculate the adjusted value\n",
    "df['SalePriceAdjusted'] = df['SalePrice'].apply(np.log)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df['SalePriceAdjusted'], bins=70)\n",
    "plt.title('Histogram of Adjusted Sale Price', fontweight=600)\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 2 - Exploring Data with Common Sense\n",
    "\n",
    "Now that we have a general understanding of the dataset, we start exploring the data with common sense by means of data visualization. Yes, in data analysis and even machine learning you are often required to use common sense. You use your common sense to make a scientific guess (i.e. hypothesis) then use data analytics methods to test your hypothesis.\n",
    "\n",
    "This dataset is about housing sales. According to common sense, housing prices depend on the following factors:\n",
    "\n",
    "* **Size of the house** (`GrLivArea`, `LotArea`, and `GarageArea`).\n",
    "\n",
    "* **Number of rooms** (`BedroomAbvGr`, `KitchenAbvGr`, `FullBath`, `HalfBath`, `BsmtFullBath`, `BsmtHalfBath`).\n",
    "\n",
    "* **How long the house has been built or remodeled** (`YearBuilt` and `YearRemodAdd`).\n",
    "\n",
    "* **Neighborhood of the house** (`Neighborhood`).\n",
    "\n",
    "#### In this challenge, use the appropriate graph type to visualize the relationships between `SalePrice` (or `SalePriceAdjusted`) and the fields above. \n",
    "\n",
    "Note that:\n",
    "\n",
    "* Transform certain columns in order to visualize the data properly based on common sense. For example:\n",
    "    * Visualizing how the number of half bathrooms affected the sale price probably does not make sense. You can create a new column to calculate the total number of bathrooms/rooms then visualize with the calculated number.\n",
    "    * `YearBuilt` and `YearRemodAdd` are year numbers not the age of the house. You can create two new columns for how long the house has been built or remodeled then visualize with the calculated columns.\n",
    "* Make comments to explain your thinking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## SIZE OF THE HOUSE\n",
    "\n",
    "# Variables\n",
    "house_size = ['GrLivArea', 'LotArea', 'GarageArea']\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(1, len(house_size), figsize=(20,5))\n",
    "\n",
    "for index in range(len(house_size)):\n",
    "    ax[index].scatter(df[house_size[index]], df[\"SalePrice\"])\n",
    "    ax[index].set_title(f\"{house_size[index]} VS SalePrice\", fontweight=700)\n",
    "    ax[index].set_xlabel(f\"{house_size[index]}\")\n",
    "    ax[index].set_ylabel(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## NUMBER OF ROOMS\n",
    "\n",
    "# Variables\n",
    "rooms = ['FullBath', 'BsmtFullBath', 'BedroomAbvGr', 'KitchenAbvGr']\n",
    "half_rooms = ['HalfBath', 'BsmtHalfBath']\n",
    "\n",
    "# Total rooms\n",
    "df['TotalRooms'] = df[rooms].sum(axis=1) + (df[half_rooms] * 0.5).sum(axis=1)\n",
    "df['TotalBathrooms'] = df[rooms[:2]].sum(axis=1) + (df[half_rooms] * 0.5).sum(axis=1)\n",
    "\n",
    "# Find median\n",
    "room_price_mean = df[['SalePrice',\"TotalRooms\"]].groupby([\"TotalRooms\"]).median()\n",
    "bathroom_price_mean = df[['SalePrice',\"TotalBathrooms\"]].groupby([\"TotalBathrooms\"]).median()\n",
    "\n",
    "# Plot\n",
    "\n",
    "## Variables\n",
    "rooms_df = [room_price_mean, bathroom_price_mean]\n",
    "titles = ['#Rooms', '#Bathrooms']\n",
    "labels = [room_price_mean.index.astype(str), bathroom_price_mean.index.astype(str)]\n",
    "f, ax = plt.subplots(len(rooms_df), 1, figsize=(10,10))\n",
    "\n",
    "## Plot\n",
    "for index in range(len(rooms_df)):\n",
    "    ax[index].bar(labels[index], rooms_df[index]['SalePrice'])\n",
    "    ax[index].set_title(f\"{titles[index]} VS SalePrice\", fontweight=700)\n",
    "    ax[index].set_xlabel(f\"{titles[index]}\")\n",
    "    ax[index].set_ylabel(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# HOW LONG THE HOUSE HAS BEEN BUILT OR REMODELED\n",
    "\n",
    "# Variables\n",
    "current_year = pd.Timestamp.today().year\n",
    "\n",
    "# Calculate years since built/remodelled\n",
    "df['YearsSinceBuilt'] =  current_year - df['YearBuilt']\n",
    "df['YearsSinceRemodel'] = current_year - df['YearRemodAdd']\n",
    "\n",
    "# Plot\n",
    "years = ['YearsSinceBuilt', 'YearsSinceRemodel']\n",
    "f, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "for index in range(len(years)):\n",
    "    ax[index].scatter(df[years[index]], df[\"SalePrice\"])\n",
    "    ax[index].set_title(f\"{years[index]} VS SalePrice\", fontweight=700)\n",
    "    ax[index].set_xlabel(f\"{years[index]}\")\n",
    "    ax[index].set_ylabel(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# NEIGHBORHOOD OF THE HOUSE\n",
    "\n",
    "# Find median\n",
    "neighborhood = df[['SalePrice',\"Neighborhood\"]].groupby([\"Neighborhood\"]).median()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(len(neighborhood)), neighborhood['SalePrice'])\n",
    "plt.title(\"Neighborhood VS SalePrice\", fontweight=700)\n",
    "plt.xticks(range(len(neighborhood)), neighborhood.index, rotation=90)\n",
    "plt.xlabel(\"Neighborhood\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bonus Challenge 2 - Exploring Data with Correlation Heatmap\n",
    "\n",
    "Now you have explored data visualizations with certain fields based on common sense. In the dataset there are many other fields that you are not sure whether they are important factors for the sale price. What is the best way to explore those fields without investigating them individually?\n",
    "\n",
    "Making scatter matrix is not an option here because there are too many fields which makes it extremely time consuming to create scatter matrix. One option you have is to create a heatmap. Heatmaps are much less expensive to create than scatter matrices. You can use heatmaps to visualize the pairwise correlations between each two variables.\n",
    "\n",
    "Here is a [reference](https://seaborn.pydata.org/examples/many_pairwise_correlations.html) you can use to learn how to creat the pairwise correlation heatmap. Your heatmap should look like below:\n",
    "\n",
    "![Corr Heatmap](images/heatmap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Correlation\n",
    "corr = df.corr()\n",
    "corr['SalePrice'].sort_values(ascending=False)[2:].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "corr['SalePrice'].sort_values(ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12,12));\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, cmap=cmap, center=0, square=True, linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In your heatmap, you can easily identify the highly correlated (either positively or negatively) variables by looking for the grids with darker colors. \n",
    "\n",
    "#### In the cell below, summarize what variables are highly correlated to the sale price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`Comments:`<br/>\n",
    "The most correlated variables are *Overall Quality*, *GrLivArea*, *GarageCars*, *TotalBathrooms* and *GarageArea*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 3 - Present Your Stories\n",
    "\n",
    "Now based on your findings from the explorations, summarize and present your stories.\n",
    "\n",
    "#### Present the top 5 factors that affect the sale price.\n",
    "\n",
    "Use the following format to present each factor:\n",
    "\n",
    "1. A title line about the factor.\n",
    "\n",
    "1. No more than 3 sentences to describe the relationship between the factor and the sale price.\n",
    "\n",
    "1. Support your point with the appropriate graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`Comments:`\n",
    "#### OverAll Quality is the deciding factor for sale price.\n",
    "As we can see in the heatmap, *overall quality* is the most correlated variable with the *sale price*. This seems logical as the better the quality, the higher the price.  \n",
    "\n",
    "#### GrLivArea & GarageArea: The size of the house directly affects the sale price.\n",
    "In the heatmap we can see that both variables are highly correlated with *sale price*. We can also see that there is a clear positive linear correlation between each of these variables and *sale price* in the scatter plots, where we analyzed the general relationship between the *sale price* and the size of the house. \n",
    "\n",
    "#### TotalBathrooms: Sale price clearly depends on the number of bathrooms in the house.\n",
    "Seeing the heatmap we can tell that the *total number of bathrooms* is associated to the *sale price* as there is a high correlation between them. In the bar plot where we analyzed the relationship between *sale price* and the number of rooms in the house, we can observe that the *sale price* increases as the number of bathrooms increase, reaching its top at 4 bathrooms. The price starts to decrease as we get passed the 4-bathroom peak. \n",
    "\n",
    "#### GarageCars: the car capacity of a garage also affects the sale price of a house.\n",
    "As we can see in the heatmap, *garage cars* is highly correlated with *sale price*. If we created a bar plot of the relationship between the number of garage cars and the sale price, we would probably see that the price increases as the number of garage cars increases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
